# -*- coding: utf-8 -*-
"""Docquery.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wyUntlKzJtOIrRKQq35mGu7F0WXVDGK7
"""

!pip install streamlit pyngrok pdfplumber cohere langchain faiss-cpu
!pip install -U langchain-community


# %%writefile app.py
 import streamlit as st
 import os
 import pdfplumber
 import cohere
 from langchain.text_splitter import RecursiveCharacterTextSplitter
 from langchain.vectorstores import FAISS
 from langchain.embeddings import CohereEmbeddings
 from langchain.chains import RetrievalQA
 from langchain.llms import Cohere as LangCohere
 import json
 
 # Initialize Cohere
 COHERE_API_KEY = "NPfdSb9lB35cJt90ewJUzIJdaArgJtxvz5GFRiVk"
 co = cohere.Client(COHERE_API_KEY)
 
 # Function to extract text from PDF
 def extract_text_from_pdf(pdf_file):
     text = ""
     with pdfplumber.open(pdf_file) as pdf:
         for page in pdf.pages:
             text += page.extract_text() + "\n"
     return text
 
 # Function to process document
 def process_document(uploaded_file):
     if uploaded_file is not None:
         file_extension = os.path.splitext(uploaded_file.name)[1].lower()
 
         if file_extension == ".txt":
             text = uploaded_file.getvalue().decode("utf-8")
         elif file_extension == ".pdf":
             text = extract_text_from_pdf(uploaded_file)
         else:
             st.error("Unsupported file format. Please upload a .txt or .pdf file.")
             return None
         return text
     return None
 
 # Streamlit UI
 st.set_page_config(page_title="Document Query System", layout="wide")
 st.title("Simplified Document Query System")
 
 # Query history storage (persistent across queries)
 if "query_history" not in st.session_state:
     st.session_state.query_history = []
 
 uploaded_file = st.file_uploader("Upload a .txt or .pdf document", type=["txt", "pdf"])
 
 if uploaded_file:
     document_text = process_document(uploaded_file)
     if document_text:
         st.success("Document uploaded successfully!")
 
         # Create embeddings and vector store
         text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
         texts = text_splitter.split_text(document_text)
 
         # âœ… FIXED: Added `user_agent="langchain"`
         embeddings = CohereEmbeddings(cohere_api_key=COHERE_API_KEY, user_agent="langchain")
         vectorstore = FAISS.from_texts(texts, embeddings)
         retriever = vectorstore.as_retriever()
 
         # Initialize QA system
         llm = LangCohere(cohere_api_key=COHERE_API_KEY)
         qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)
 
         # User input for queries
         query = st.text_input("Ask a question from the document:")
         if query:
             response = qa_chain.run(query)
             st.write("**Answer:**", response)
 
             # Store in session history
             st.session_state.query_history.append({"query": query, "response": response})
 
         # Show query history
         if st.button("Show Query History"):
             st.json(st.session_state.query_history)
 
         # Export results
         if st.button("Export Results"):
             with open("query_results.json", "w") as f:
                 json.dump(st.session_state.query_history, f, indent=4)
             st.success("Results exported as query_results.json")


!pkill  -f ngrok

from pyngrok import ngrok

# Ensure ngrok is authenticated
NGROK_AUTH_TOKEN = "2v04hsG6vPnKRcp9Zm7xTzsWHwo_5U6YWAwEpLC65Fj83VJyT"  # Replace with your actual token
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

# Start tunnel
public_url = ngrok.connect(8501).public_url
print(f"Ngrok URL: {public_url}")

!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 &